\documentclass[11pt]{amsart}
\usepackage{amssymb,amsfonts}
\usepackage{euscript,mathrsfs}
\usepackage{latexsym}
\usepackage{xspace}
\usepackage{amscd}
\usepackage{amsmath}
\usepackage{color}
\usepackage{cite}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amsthm,amsopn,graphicx,microtype}
\usepackage{url}

\theoremstyle{plain}% default
\newtheorem{thm}{Theorem}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollary}
\newtheorem{algorithm}{Algorithm}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{exmp}[thm]{Example}

\theoremstyle{remark}
\newtheorem*{rem}{Remark}
\newtheorem*{note}{Note}
\newtheorem{case}{Case}

\newcommand{\Mac}{Macaulay2\xspace}
\newcommand{\SOS}{\textsc{SOS}\xspace}

\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\kk}{\mathbb{K}}

\begin{document}

\title[SOS.m2]{Sums of squares in Macaulay2}

\author{Diego Cifuentes}
\address{Massachusetts Institute of Technology \\ Cambridge, MA, USA}
\email{diegcif@mit.edu}

\author{Thomas Kahle}
\address{Otto-von-Guericke University \\ Magdeburg, Germany}
\email{thomas.kahle@ovgu.de}

\author{Pablo A. Parrilo}
\address{Massachusetts Institute of Technology \\ Cambridge, MA, USA}
\email{parrilo@mit.edu}


\begin{abstract}
  The package \SOS implements sums of squares (SOS) decompositions in
  Macaulay2.  
  It is based on methods to rationalize SOS decompositions due to Parrilo and Peyrl.
  The package features a data type for SOS decompositions, support for external SDP solvers, and optimization over varieties.
\end{abstract}

\maketitle

\section{Introduction}
\label{s:intro}

Let $\kk = \QQ$ or $\kk = \RR$ denote the rational or real numbers and let $R = \kk[x_{1},\dots,x_{n}]$ be the polynomial ring.  
An element $f\in R$ is \emph{nonnegative} if $f(x) \ge 0$ for all $x \in \RR^{n}$.  
The element $f$ is a \emph{sum of squares} or \emph{SOS} if there exist polynomials $f_{1},\dots,f_{m} \in R$ and positive scalars $\lambda_{1},\dots,\lambda_{m}\in \kk$ such that $f=\sum_{i}\lambda_i f_{i}^{2}$.
The scalars are not necessary when the field is $\kk=\RR$.
Clearly, an SOS polynomial is nonnegative, but not every nonnegative polynomial is SOS.
Classically, Hilbert characterized in which cases sums of squares coincide with nonnegative polynomials as univariate polynomials, quadratic polynomials and bivariate quartics.  
For an introduction to the area we recommend~\cite{scheiderer2009positivity,blekherman2012semidefinite}.

The purpose of the \SOS package is to deal with sums of squares in Macaulay2.
A particular focus is on trying to find rational SOS decompositions of polynomials with rational coefficients (whenever they exist).

The package contains the data type \verb|SOSPoly| to store SOS decompositions and perform basic operations on them.
The most basic method is \verb|solveSOS|.
It takes a polynomial and tries to write it as a sum of squares:
{\small
\verb|solveSOS|:
\begin{verbatim}
i6 : R = QQ[x,y];
i7 : f = 2*x^4+5*y^4-2*x^2*y^2+2*x^3*y;
i8 : sosPoly solveSOS f
Executing CSDP
Status: SDP solved, primal-dual feasible
o8 = coeffs: {5, 43/20, 231773/344000}              
     gens: {- 83/200 x^2  + y^2 , 20/43 x^2  + x*y, x^2 }
\end{verbatim}
}
\noindent
This output has been reformatted for the paper, but contains the same information as the actual output.
The type \verb|SOSPoly| stores the coefficients $\lambda_{i}$ (under \verb|coeffs|) and polynomials $f_{i}$ (under \verb|gens|) such that $f = \sum_{i}\lambda_{i}f_{i}^{2}$.

In the above example the package is configured to use the SDP solver CSDP which is called by \verb|solveSOS|.
The SOS decomposition of the input polynomial solves an SDP numerically and then rounds the result to obtain a rational SOS decomposition~\cite{peyrl2008computing}.
The return value of \verb|solveSOS| is an object \verb|SDPResult| which contains details about the numerical computation.
Then \verb|sosPoly| extracts the SOS.
In this case there are three squares:
\[
  f = 5(-\tfrac{83}{200} x^{2}+y^{2})^{2} + \tfrac{43}{20}
  (\tfrac{20}{43}x^{2} + xy)^{2} + \tfrac{231773}{344000} (x^{2})^{2}.
\]
This decomposition is not the simplest one, but it is fully rational. 
Simplifications can be done in post-processing.

The package also allows to compute SOS decompositions in quotient rings.
This can be useful to prove nonnegativity of a polynomial on a variety.  
The following example is taken from~\cite{parrilo2005exploiting}.  
Consider the problem of proving that the polynomial $f = 10{-}x^2{-}y$ is nonnegative on the circle defined by $g = x^2 {+} y^2 {-} 1$.
To do this we check if the image of $f$ in $\QQ[x,y]/g$ is a sum-of-squares.
For such a computation, a degree bound must be given by the user as it is not a priori obvious how to choose a monomial basis.
This is the second argument to \verb|solveSOS| in the following example.
{\small
\begin{verbatim}
i2 : R = QQ[x,y]/ideal(x^2 + y^2 - 1);
i3 : f = 10-x^2-y;
i4 : sosPoly solveSOS (f, 2, TraceObj=>true)
Executing CSDP
Status: SDP solved, primal-dual feasible
o4 = coeffs: {9, 35/36}      
     gens: {- 1/18 y + 1, y} 
\end{verbatim}
}
\noindent
In the above computation the option \verb|TraceObj=>true| was used to minimize the number of summands in the SOS decomposition (see Section~\ref{s:arguments}).

% \subsection{History of the package}
% The new version of \SOS was developed starting with version 1.5 of the
% \SOS package due to Parrilo and Peyrl~\cite{peyrl2008computing}.
% The idea of rational reconstruction of SOS decompositions goes back to
% that work.

\section{Sums of squares in ideals}
Let $I \subset \kk[x_{1},\dots,x_{n}]$ be an ideal.  The \SOS package can be used to find a sum of squares in~$I$.
Of course every ideal contains the squares of its generators.
The aim is to find low degree sums of squares.
An alternative formulation of the same problem is to consider the quotient $S = \kk[x_{1},\dots,x_{n}]/I$ and write $0\in S$ as a sum of squares.
Both formulations of the problem are available in the \SOS package.
The first takes a one row matrix of polynomials and tries to find a sum of squares that is a polynomial combination of them.
For this, \verb|sosInIdeal| needs to be called with a matrix of polynomials and a degree bound on the desired sum of squares:
{\small
\begin{verbatim}
i1 : R = QQ[x,y,z];
i2 : h = matrix {{x^2+y^2+y, y-z^2}};
i3 : (sol,mult) = sosInIdeal (h, 2);
i4 : sosPoly sol
o4 = coeffs: {63/4, 63/4, 63/4}
     gens: {x, y, z}
i5 : h * mult == sosPoly sol
o5 = true
\end{verbatim}
}
The same computation can be carried out in the quotient ring.
In this case the argument to \verb|sosInIdeal| is simply the quotient ring.
{\small
\begin{verbatim}
i6 : S = R/ideal h;
i7 : sosPoly sosInIdeal (S, 2);
o7 = coeffs: {59/2, 59/2, 59/2}
     gens: {x, y, z}
\end{verbatim}
}
The SOS polynomial obtained by \verb|sosInIdeal| gives information about the real radical of the ideal $I$.
In particular, we can see that the real radical of the ideal from above is generated by $\langle x,y,z\rangle$.

\section{SOS decomposition of ternary forms}

Hilbert showed that any nonnegative form $f\in \kk[x,y,z]$ can be decomposed as a quotient of sums of squares.
We can obtain this decomposition by iteratively calling \verb|sosInIdeal|.
Specifically, one can first find a multiplier $q_{1}$ such that $q_{1}f$ is SOS.
Since $q_1$ is also nonnegative, we can then search for a multiplier $p_{1}$ such that $p_{1}q_{1}$ is SOS, and so on.
The main observation is that the necessary degree of $p_{1}$ is lower than that of $q_{1}$~\cite{de2004products}.
Hence this procedure terminates, and we can write 
\[
  f = \frac{p_{1}\cdots p_{s}}{q_{1}\cdots q_{t}} \qquad \text {
    $p_{i},q_{i}$ SOS}.
\]

As an illustration, we will write the Motzkin polynomial as a quotient of SOS polynomials.
We first use the function \verb|library|, which contains a small library of interesting nonnegative forms.
{\small
\begin{verbatim}
i2 : R = QQ[x,y,z]
i3 : f = library ("Motzkin", {x,y,z})
      4 2    2 4     2 2 2    6
o3 = x y  + x y  - 3x y z  + z
\end{verbatim}
}
\noindent 
We now apply the function \verb|sosdecTernary|, which implements the iterative algorithm from above.
{\small
\begin{verbatim}
i4 : (nums,dens) = sosdecTernary f;
Executing CSDP
i5 : first nums
o5 = coeffs: {2059/64, 28, 3851/256, 3851/256, 2059/256}
     gens: {x^2*y^2-z^4, -(1/2)*x^3*y-(1/2)*x*y^3+x*y*z^2, ... }
i6 : first dens
     coeffs: {2059/64, 3851/256, 3851/256}
     gens: {x, y, z}
\end{verbatim}
}
The result consist of two sums of squares only, the second being the denominator.
Seeing this, one might get the idea that the product of $(x^{2}+y^{2}+z^{2})$ and the Motzkin polynomial is a sum of squares.
That this is the case can easily be checked with \verb|solveSOS (x^2+y^2+z^2)*f|.

\section{Parametric SOS problems}

SOS problems can also be solved parametrically.
For this, assume now that $x \mapsto f(x;t)$ is a polynomial function, that depends affinely on some parameters~$t$.
The command \verb|solveSOS| allows to search for values of the parameters such that the polynomial is a SOS.
In the following example, we increase two terms of the Robinson polynomial so that it becomes SOS.

{\small
\begin{verbatim}
i1 : R = QQ[x,y,z][s,t]
i2 : g = library("Robinson", {x,y,z}) + s*x^6 + t*y^6
i3 : sol = solveSOS g;
Executing CSDP
Status: SDP solved, primal-dual feasible
i4 : sol#Parameters
o15 = | 34 |
      | 34 |
\end{verbatim}
}

It is also possible find the values of the parameters that optimize a given linear function.
This allows to find lower bounds for a polynomial function $f(x)$,
by finding the largest $t$ such that $f(x)-t$ is SOS.
Here we apply this method to the dehomogenized Motzkin polynomial.
{\small
\begin{verbatim}
i12 : R = QQ[x,z][t];
i13 : f = library ("Motzkin", {x,1,z});
i14 : sol = solveSOS (f-t, -t, RoundTol=>12);
Executing CSDP
Status: SDP solved, primal-dual feasible
i15 : sol#Parameters
o15 = | -729/4096 |
\end{verbatim}
}
\noindent
The function \verb|lowerBound| does this construction automatically.
{\small
\begin{verbatim}
i1 : R = QQ[x,z];
i2 : f = library ("Motzkin", {x,1,z});
i3 : (t,sol) = lowerBound (f, RoundTol=>12);
Executing CSDP
Status: SDP solved, primal-dual feasible
i16 : t
o16 = - 729/4096
\end{verbatim}
}

\section{Polynomial optimization}

Often times in application one needs to find lower bounds for polynomials subject to some polynomial constraints.
More precisely, consider the problem
\begin{align*}
  \min_{x\in X} \quad f(x),
  \quad \text{ where }\quad
  X := \{x \in \RR^n : h_1(x)=\dots=h_m(x)=0\},
\end{align*}
and where $f, h_1,\dots,h_m$ are polynomials.
The \SOS package provides two ways to compute lower bound for such a problem.
The most elegant approach is to construct the associated quotient ring, and then call \verb|lowerBound|.
This will look for the largest $t$ such that $f(x)-t$ is SOS (in the quotient ring).
A degree bound must be given by the user.

{\small
\begin{verbatim}
i6 : R = QQ[x,y]/ideal(x^2 - x, y^2 - y);
i7 : f = x - y;
i8 : (t,sol) = lowerBound(f,2);
Executing CSDP
Status: SDP solved, primal-dual feasible
i9 : t
o9 = -1
i10 : f - t == sosPoly sol
o10 = true
\end{verbatim}
}

Calling \verb|lowerBound| as above is the most practical approach, but it requires knowledge of a Gröbner basis, which is computed when constructing the quotient ring.
If no Gröbner basis is available there is an alternative way to call \verb|lowerBound| with just the equations $h_1,\dots,h_m$ as the input.
The method will then look for polynomial multipliers $l_i(x)$ such that $f(x) - t + \sum_i l_i(x)h_i(x)$ is SOS.
This results in larger SDP's and possibly weaker bounds.

{\small
\begin{verbatim}
i11 : R = QQ[x,y];
i12 : f = x - y;
i13 : h = matrix{{x^2 - x, y^2 - y}};
i14 : (t,sol,mult) = lowerBound (f, h, 2);
Executing CSDP
Status: SDP solved, primal-dual feasible
i15 : t
o15 = -1
i16 : f - t + h*mult == sosPoly sol
o16 = true
\end{verbatim}
}

Lower bounds for polynomial optimization problems critically depend on the degree bound chosen.
While higher degree bounds lead to better bounds, the computational complexity escalates quite rapidly.
Nonetheless, low degree SOS lower bounds perform very well in several applications.
In some cases, the minimizer might also be recovered from the \verb|SDPResult| with the method \verb|recoverSolution|.

{\small
\begin{verbatim}
i17 : recoverSolution sol
o17 = {x => 1.77345e-9, y => 1}
\end{verbatim}
}

\section{Optional arguments}
\label{s:arguments}

\subsection*{SDP Solver}
The \SOS package relies on numerical SDP solvers for SOS decompositions.  
While it does have a built in solver in the \Mac language, larger examples require an external solver.
At the moment the package has interfaces to the open source solvers CSDP~\cite{borchers1999csdp} and SDPA~\cite{yamashita2003implementation}, and the commercial solver MOSEK~\cite{mosek}.
In our experience CSDP and MOSEK give the best results.
The solver can be specified with the optional argument \verb|Solver|.
We refer to the package documentation for further information.

\subsection*{Rounding tolerance}
The method \verb|lowerBound| has the optional argument \verb|RoundTol|, which specifies the precision of the rational rounding.
Smaller values of \verb|RoundTol| lead to simpler bounds (smaller denominators), at the expense of a loss in optimality.
The rounding may be skipped by setting it to infinity.

\subsection*{Trace objective}
This option tells the SDP solver to use the matrix trace as an objective function for the SDP.
This is a known heuristic to minimize the number of summands in a sum of squares.


\section*{Acknowledgment}
\label{sec:acknowledgement}
The authors would like to thank the Max-Planck-Institute MiS in Leipzig for hosting the \Mac workshop in May 2018 during which the renewal of the SOS package started.
Nidhi Kainsa and Anton Leykin contributed parts of the code.
Thomas Kahle is supported by German Research Foundation under grant 314838170, GRK 2297 MathCoRe.

\bibliographystyle{amsplain}
\bibliography{sos}

\end{document}  

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
