\documentclass[11pt]{amsart}
\usepackage{amssymb,amsfonts}
\usepackage{euscript,mathrsfs}
\usepackage{latexsym}
\usepackage{xspace}
\usepackage{amscd}
\usepackage{amsmath}
\usepackage{color}
\usepackage{cite}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amsthm,amsopn,graphicx,microtype}
\usepackage{url}

\theoremstyle{plain}% default
\newtheorem{thm}{Theorem}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollary}
\newtheorem{algorithm}{Algorithm}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{exmp}[thm]{Example}

\theoremstyle{remark}
\newtheorem*{rem}{Remark}
\newtheorem*{note}{Note}
\newtheorem{case}{Case}

\newcommand{\Mac}{Macaulay2\xspace}
\newcommand{\SOS}{\textsc{SOS}\xspace}
\newcommand{\SDP}{\textsc{SemidefiniteProgramming}\xspace}

\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\kk}{\mathbb{K}}

\begin{document}

\title[Sums of squares in Macaulay2]{Sums of squares in Macaulay2}

\author{Diego Cifuentes}
\address{Massachusetts Institute of Technology \\ Cambridge, MA, USA}
\email{diegcif@mit.edu}

\author{Thomas Kahle}
\address{Otto-von-Guericke University \\ Magdeburg, Germany}
\email{thomas.kahle@ovgu.de}

\author{Pablo A. Parrilo}
\address{Massachusetts Institute of Technology \\ Cambridge, MA, USA}
\email{parrilo@mit.edu}


\begin{abstract}
  The package \SOS implements sums-of-squares (SOS) decompositions in
  \Mac.
  It is based on methods to rationalize SOS decompositions due to Parrilo and Peyrl.
  The package features a data type for SOS decompositions, support for external SDP solvers, and optimization over varieties.
\end{abstract}

\maketitle

\section{Introduction}
\label{s:intro}

Let $\kk \!=\! \QQ$ or $\kk \!=\! \RR$ be the rational or real numbers and $R = \kk[x_{1},\dots,x_{n}]$ be the polynomial ring.
An element $f\!\in\! R$ is \emph{nonnegative} if $f(x) \!\ge\! 0$ for all $x \!\in\! \RR^{n}$.
And $f$ is a \emph{sum-of-squares} or \emph{SOS} if there are polynomials $f_{1},\dots,f_{m} \!\in\! R$ and positive scalars $\lambda_{1},\dots,\lambda_{m} \!\in\! \kk$ such that $f=\sum_{i}\lambda_i f_{i}^{2}$.
The scalars are not necessary when the field is $\kk\!=\!\RR$.
Clearly, an SOS polynomial is nonnegative, but not every nonnegative polynomial is SOS.
Classically, Hilbert characterized in which cases sums-of-squares coincide with nonnegative polynomials as univariate polynomials, quadratic polynomials and bivariate quartics.  
For an introduction to the area we recommend~\cite{scheiderer2009positivity,blekherman2012semidefinite}.

The \SOS package allows to perform computations with sums-of-squares in \Mac.
A particular focus is on trying to find rational SOS decompositions of polynomials with rational coefficients (whenever they exist).

Consider the basic problem of deciding if a polynomial is a sum-of-squares.
Let $f \!\in\! R$ of degree~$2d$,
and $v \!\in\! R^N$ a vector with all the $N \!=\! \binom{n+d}{d}$ monomials of degree $\leq\!d$.
The following fundamental result holds:
\begin{align*}
  f \text{ is SOS } 
  \qquad\iff\qquad
  \exists\, Q\in \mathbb{S}_+^N \text{ such that } f = v^T Q v,
\end{align*}
where $\mathbb{S}_+^N$ is the cone of $N{\times} N$ symmetric positive semidefinite matrices.
% This reduces the problem to finding a matrix $Q$ as above. 
This reduces the problem to finding a \emph{Gram matrix} $Q$ as above, which can be done efficiently with \emph{semidefinite programming} (SDP).

The method \verb|solveSOS| performs the above computation.
We use it here to verify that $f = 2 x^4 {+} 5 y^4 {-} 2 x^2 y^2 {+} 2 x^3 y$ is a sum-of-squares:
{\small
\begin{verbatim}
i1 : R = QQ[x,y];
i2 : f = 2*x^4+5*y^4-2*x^2*y^2+2*x^3*y;
i3 : sol = solveSOS f;
Executing CSDP
Status: SDP solved, primal-dual feasible
\end{verbatim}
}
\noindent
The ``Status'' line indicates that a Gram matrix was found, so $f$ is indeed~SOS.
In the above example the package called the SDP solver CSDP~\cite{borchers1999csdp} in the background.
This solver comes with \Mac and is the default.
The output of \verb|solveSOS| is an object of type \verb|SDPResult|.
It contains, in particular, the Gram matrix~$Q$ and the monomial vector~$v$.
{\small
\begin{verbatim}
i4 : (Q,v) = ( sol#GramMatrix, sol#Monomials )
o4 = ( | 2      1     -83/40 |,   | x2 | )
       | 1      43/20 0      |    | xy | 
       | -83/40 0     5      |    | y2 | 
\end{verbatim}
}
\noindent
Although the result of the SDP solver is numerical, Macaulay2 rounds it to obtain a rational Gram matrix~\cite{peyrl2008computing}.

The method \verb|sosPoly| extracts the SOS decomposition from the returned \verb|SDPResult|.
This is done via a Cholesky factorization of the Gram matrix.
For the function $f$ from above we get three squares:
\[
  f = 5(-\tfrac{83}{200} x^{2}+y^{2})^{2} + \tfrac{43}{20}
  (\tfrac{20}{43}x^{2} + xy)^{2} + \tfrac{231773}{344000} (x^{2})^{2}.
\]
{\small
\begin{verbatim}
i5 : sosPoly sol
o5 = coeffs: {5, 43/20, 231773/344000}
     gens: {- 83/200 x^2  + y^2 , 20/43 x^2  + x*y, x^2 }
\end{verbatim}
}
\noindent
The last output is an object of type \verb|SOSPoly|.
This type stores the coefficients $\lambda_{i}$ (under \verb|coeffs|) and polynomials $f_{i}$ (under \verb|gens|) such that $f = \sum_{i}\lambda_{i}f_{i}^{2}$.
%The decomposition obtained is not the simplest one, but it is fully rational.
%It can be simplified in post-processing.

The method \verb|solveSOS| also allows to compute SOS decompositions in quotient rings.
This can be useful to prove nonnegativity of a polynomial on a variety.
We take an example from~\cite{parrilo2005exploiting}.
Consider proving that $f = 10{-}x^2{-}y$ is nonnegative on the circle defined by $g = x^2 {+} y^2 {-} 1$.
To do this, we check if the image of $f$ in $\QQ[x,y]/\langle g\rangle$ is a sum-of-squares.
For such a computation, a degree bound~$2d$ must be given by the user, as otherwise it is not obvious how to choose the monomial vector~$v$.
In this case we set $2d=2$.
{\small
\begin{verbatim}
i1 : R = QQ[x,y]/ideal(x^2 + y^2 - 1);
i2 : f = 10-x^2-y;  d = 1;
i3 : sosPoly solveSOS (f, 2*d, TraceObj=>true)
Executing CSDP
Status: SDP solved, primal-dual feasible
o3 = coeffs: {9, 35/36}
     gens: {- 1/18 y + 1, y}
\end{verbatim}
}
\noindent
In the above computation the option \verb|TraceObj=>true| was used to reduce the number of summands in the SOS decomposition (see Section~\ref{s:arguments}).

% \subsection{History of the package}
% The new version of \SOS was developed starting with version 1.5 of the
% \SOS package due to Parrilo and Peyrl~\cite{peyrl2008computing}.
% The idea of rational reconstruction of SOS decompositions goes back to
% that work.

\section{Sums of squares in ideals}
Let $I \subset \kk[x_{1},\dots,x_{n}]$ be an ideal.  
Given a bound $2d\in\NN$, consider the problem of finding a nonzero SOS polynomial of degree $\leq \!2d$ in the ideal~$I$.
If one of the generators of $I$ has degree $\leq \!d$, then the problem is trivial.
But otherwise the problem can be hard.
The method \verb|sosInIdeal| can be used to solve it.
One of the main motivations for this problem is that it reveals information about the \emph{real radical} of the ideal~$I$.
Indeed, if $f = \sum \lambda_i f_i^2 \in I$ then each of the factors $f_i$ must lie in the real radical of~$I$.

Given generators of the ideal $I=\langle h_1,\dots,h_m\rangle$, we may solve this problem by looking for some polynomial multipliers $l_i(x)$ such that  $\sum_i l_i(x) h_i(x)$ is a sum-of-squares.
The method \verb|sosInIdeal| allows to find these multipliers.
The input of the method is a matrix containing the generators, and the degree bound~$2d$.
We illustrate this for the ideal $I=\langle x^2{+}y^2{+}y, y{-}z^2 \rangle$.
{\small
\begin{verbatim}
i1 : R = QQ[x,y,z];  d = 1;
i2 : h = matrix {{x^2+y^2+y, y-z^2}};
i3 : (sol,mult) = sosInIdeal (h, 2*d);
i4 : sosPoly sol
o4 = coeffs: {63/4, 63/4, 63/4}
     gens: {x, y, z}
i5 : h * mult == sosPoly sol
o5 = true
\end{verbatim}
}
\noindent
An alternative way to approach this problem is to construct the quotient $S = \kk[x_{1},\dots,x_{n}]/I$ and then write $0\in S$ as a sum-of-squares.
In this case the argument to \verb|sosInIdeal| is simply the quotient ring~$S$.
{\small
\begin{verbatim}
i6 : S = R/ideal h;
i7 : sosPoly sosInIdeal (S, 2*d);
o7 = coeffs: {59/2, 59/2, 59/2}
     gens: {x, y, z}
\end{verbatim}
}
\noindent
In both cases we obtained a multiple of the SOS polynomial $x^2{+}y^2{+}z^2$.
From this computation we conclude that the real radical of~$I$ is the ideal $\langle x,y,z\rangle$.

\section{SOS decomposition of ternary forms}

Hilbert showed that any nonnegative form $f\in \kk[x,y,z]$ can be decomposed as a quotient of sums-of-squares.
We can obtain this decomposition by iteratively calling \verb|sosInIdeal|.
Specifically, one can first find a multiplier $q_{1}$ such that $q_{1}f$ is SOS.
Since $q_1$ is also nonnegative, we can then search for a multiplier $p_{1}$ such that $p_{1}q_{1}$ is SOS, and so on.
The main observation is that the necessary degree of $p_{1}$ is lower than that of $q_{1}$~\cite{de2004products}.
Hence this procedure terminates, and we can write
\[
  f = \frac{p_{1}\cdots p_{s}}{q_{1}\cdots q_{t}} \qquad \text {
    $p_{i},q_{i}$ SOS}.
\]

As an illustration, we write the Motzkin polynomial as a quotient of SOS polynomials.
We first use the function \verb|library|, which contains a small library of interesting nonnegative forms.
{\small
\begin{verbatim}
i1 : R = QQ[x,y,z]
i2 : f = library ("Motzkin", {x,y,z})
      4 2    2 4     2 2 2    6
o2 = x y  + x y  - 3x y z  + z
\end{verbatim}
}
\noindent
We now apply the function \verb|sosdecTernary|, which implements the iterative algorithm from above.
{\small
\begin{verbatim}
i3 : (nums,dens) = sosdecTernary f;
Executing CSDP
i4 : first nums
o4 = coeffs: {2059/64, 28, 3851/256, 3851/256, 2059/256}
     gens: {x^2*y^2-z^4, -(1/2)*x^3*y-(1/2)*x*y^3+x*y*z^2, ... }
i5 : first dens
o5 = coeffs: {2059/64, 3851/256, 3851/256}
     gens: {x, y, z}
\end{verbatim}
}
\noindent
The result consists of two SOS polynomials, the second being the denominator.
The above computation reveals that the product of the Motzkin polynomial and $(x^2{+}y^2{+}z^2)$ is a sum-of-squares.
This can be checked independently with the command \verb|solveSOS (x^2+y^2+z^2)*f|.

\section{Parametric SOS problems}

The \SOS package can also solve parametric problems.
Assume now that $x \mapsto f(x;t)$ is a polynomial function, that depends affinely on some parameters~$t$.
The command \verb|solveSOS| allows to search for values of the parameters such that the polynomial is a SOS.
%In the following example, we increase two terms of the Robinson polynomial so that it becomes SOS.
In the following example, we change two coefficients of the Robinson polynomial so that it becomes SOS.
{\small
\begin{verbatim}
i1 : R = QQ[x,y,z][s,t]; -- s,t are treated as parameters
i2 : g = library("Robinson", {x,y,z}) + s*x^6 + t*y^6;
i3 : sol = solveSOS g;
Executing CSDP
Status: SDP solved, primal-dual feasible
i4 : sol#Parameters
o4 = | 34 |
     | 34 |
\end{verbatim}
}

It is also possible find the values of the parameters that optimize a given linear function.
This allows to find lower bounds for a polynomial function $f(x)$,
by finding the largest $t$ such that $f(x)-t$ is SOS.
Here we apply this method to the dehomogenized Motzkin polynomial.

{\small
\begin{verbatim}
i1 : R = QQ[x,z][t]; -- t is treated as a parameter
i2 : f = library ("Motzkin", {x,1,z});
i3 : sol = solveSOS (f-t, -t, RoundTol=>12);
Executing CSDP
Status: SDP solved, primal-dual feasible
i4 : sol#Parameters
o4 = | -729/4096 |
\end{verbatim}
}

\noindent
Alternatively, the method \verb|lowerBound| can be called with input~$f(x)$.
The method internally declares a new parameter~$t$ and optimizes $f(x)-t$.
%The function \verb|lowerBound| does this construction automatically.
{\small
\begin{verbatim}
i1 : R = QQ[x,z];
i2 : f = library ("Motzkin", {x,1,z});
i3 : (t,sol) = lowerBound (f, RoundTol=>12);
Executing CSDP
Status: SDP solved, primal-dual feasible
i4 : t
o4 = - 729/4096
\end{verbatim}
}

\section{Polynomial optimization}

Oftentimes in application one needs to find lower bounds for polynomials subject to some polynomial constraints.
More precisely, consider the problem
\begin{align*}
  \min_{x\in \RR^n} \quad f(x)
  \quad \text{ such that }\quad
  h_1(x)=\dots=h_m(x)=0,
\end{align*}
where $f, h_1,\dots,h_m$ are polynomials.
The \SOS package provides two ways to compute a lower bound for such a problem.
The most elegant approach is to construct the associated quotient ring, and then call \verb|lowerBound|.
This will look for the largest $t$ such that $f(x)-t$ is SOS (in the quotient ring).
A degree bound~$2d$ must be given by the user.

{\small
\begin{verbatim}
i1 : R = QQ[x,y]/ideal(x^2 - x, y^2 - y);
i2 : f = x - y;  d = 1;
i3 : (t,sol) = lowerBound(f,2*d);
Executing CSDP
Status: SDP solved, primal-dual feasible
i4 : t
o4 = -1
i5 : f - t == sosPoly sol
o5 = true
\end{verbatim}
}

Calling \verb|lowerBound| as above is conceptually simple, but requires knowledge of a Gröbner basis, which is computed when constructing the quotient ring.
If no Gröbner basis is available there is an alternative way to call \verb|lowerBound| with just the equations $h_1,\dots,h_m$ as the input.
The method will then look for polynomial multipliers $l_i(x)$ such that $f(x) - t + \sum_i l_i(x)h_i(x)$ is SOS.
This may result in larger SDP's and weaker bounds.

{\small
\begin{verbatim}
i1 : R = QQ[x,y];
i2 : f = x - y;  d = 1;
i3 : h = matrix{{x^2 - x, y^2 - y}};
i4 : (t,sol,mult) = lowerBound (f, h, 2*d);
Executing CSDP
Status: SDP solved, primal-dual feasible
i5 : t
o5 = -1
i6 : f - t + h*mult == sosPoly sol
o6 = true
\end{verbatim}
}

Lower bounds for polynomial optimization problems critically depend on the degree bound chosen.
While higher degree bounds lead to better bounds, the computational complexity escalates quite rapidly.
Nonetheless, low degree SOS lower bounds perform very well in several applications.
In some cases, the minimizer might also be recovered from the \verb|SDPResult| with the method \verb|recoverSolution|.

{\small
\begin{verbatim}
i7 : recoverSolution sol
o7 = {x => 1.77345e-9, y => 1}
\end{verbatim}
}

\section{Optional arguments}
\label{s:arguments}

\subsection*{SDP Solver}
The optional argument \verb|Solver| is available for many package methods and allows to select the SDP solver.
These solvers are interfaced via the auxiliary Macaulay2 package \SDP.
The package provides interfaces to the open source solvers CSDP~\cite{borchers1999csdp} and SDPA~\cite{yamashita2003implementation}, and the commercial solver MOSEK~\cite{mosek}.
There is also a built-in solver in the \Mac language.
In our experience CSDP and MOSEK give the best results.
CSDP is provided as part of \Mac and configured as the default.
% We refer to the package documentation for further information.

\subsection*{Rounding tolerance}
The method \verb|lowerBound| has the optional argument \verb|RoundTol|, which specifies the precision of the rational rounding.
Smaller values of \verb|RoundTol| lead to simpler bounds (smaller denominators), at the expense of a loss in optimality.
The rational rounding may be skipped by setting it to infinity.

\subsection*{Trace objective}
The option \verb|TraceObj| tells the SDP solver to minimize the trace of the Gram matrix.
This is a known heuristic to reduce the number of summands in the sum-of-squares decomposition.


\section*{Acknowledgment}
\label{sec:acknowledgement}
The authors would like to thank Bernd Sturmfels and the Max-Planck-Institute MiS for hosting the \Mac workshop in May 2018.
We thank Ilir Dema, Nidhi Kainsa and Anton Leykin, who contributed to the code.
Parts of this work were done while Diego Cifuentes visited the Max-Planck-Institute MiS, and while the first two authors visited ICERM supported by NSF grant No. DMS-1439786.
Thomas Kahle is supported by the German Research Foundation under grant 314838170, GRK 2297 MathCoRe.

\bibliographystyle{amsplain}
\bibliography{sos}

\end{document}

%%% Local Variables:
%%% TeX-master: t
%%% TeX-PDF-mode: t
%%% eval: (auto-fill-mode -1)
%%% mode: latex
%%% End:
